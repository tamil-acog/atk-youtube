{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import re\n",
    "import time, datetime\n",
    "import bisect\n",
    "from langchain.llms import OpenAI\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_code = 'aVQQuoToTJA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chapters_and_time_and_images(video_code: str) -> List[str]:\n",
    "\n",
    "    api_response_object: requests.Response = requests.get(f'https://yt.lemnoslife.com/videos?part=chapters&id={video_code}')\n",
    "    api_response = api_response_object.json()\n",
    "\n",
    "    chapters: List = []\n",
    "    start_time: List= []\n",
    "    images_link: List = []\n",
    "    number_of_titles:int = len(api_response['items'][0]['chapters']['chapters'])\n",
    "    \n",
    "    for i in range(0,number_of_titles):\n",
    "        chapters.append(api_response['items'][0]['chapters']['chapters'][i]['title'])\n",
    "        start_time.append(api_response['items'][0]['chapters']['chapters'][i]['time'])\n",
    "        images_link.append(api_response['items'][0]['chapters']['chapters'][i]['thumbnails'][1]['url'])\n",
    "\n",
    "    \n",
    "    # if 0 not in start_time:\n",
    "    #     start_time.insert(0, 0)\n",
    "    \n",
    "    return chapters, start_time, images_link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://dev-pypi.aganitha.ai\n",
      "Collecting pillow\n",
      "  Downloading Pillow-9.4.0-2-cp311-cp311-macosx_10_10_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pillow\n",
      "Successfully installed pillow-9.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Hallucinating Symmetric Protein Assemblies',\n",
       "  'Incorporating these Short Linear Motives into Genova Design Protein Scaffolds',\n",
       "  'Structural Addition',\n",
       "  'Problem Statement',\n",
       "  'Sampling Temperature',\n",
       "  'Amino Acid Biases',\n",
       "  'Sequence Recovery Maximum Accuracy',\n",
       "  'Solution Conditions',\n",
       "  'The Membrane Proteins',\n",
       "  'Is Body Impedance Score Dependent on the Decoding Order',\n",
       "  'What Applications Do You Envision Mpn Will Be Used for',\n",
       "  'If a Background Has More Diversity at Lower Temperatures Could that Mean It Is More Designable'],\n",
       " [107, 336, 593, 716, 1548, 1668, 2424, 2667, 2917, 2938, 2965, 3075],\n",
       " ['https://i.ytimg.com/vi/aVQQuoToTJA/hqdefault_114433.jpg?sqp=-oaymwE9CNACELwBSFryq4qpAy8IARUAAAAAGAElAADIQj0AgKJDeAHwAQH4Af4JgALQBYoCDAgAEAEYZCBlKFQwDw==&rs=AOn4CLAWsuPZH7ETroeyS2k9HtBAn3XRpA',\n",
       "  'https://i.ytimg.com/vi/aVQQuoToTJA/hqdefault_337133.jpg?sqp=-oaymwE9CNACELwBSFryq4qpAy8IARUAAAAAGAElAADIQj0AgKJDeAHwAQH4Af4JgALQBYoCDAgAEAEYZCBlKFQwDw==&rs=AOn4CLCah5fg9rV46D75l-2vsn35EZsuEg',\n",
       "  'https://i.ytimg.com/vi/aVQQuoToTJA/hqdefault_623133.jpg?sqp=-oaymwE9CNACELwBSFryq4qpAy8IARUAAAAAGAElAADIQj0AgKJDeAHwAQH4Af4JgALQBYoCDAgAEAEYZCBlKFQwDw==&rs=AOn4CLCz5xYdUvNMsV5zK-ps9NkAccvoFg',\n",
       "  'https://i.ytimg.com/vi/aVQQuoToTJA/hqdefault_724766.jpg?sqp=-oaymwE9CNACELwBSFryq4qpAy8IARUAAAAAGAElAADIQj0AgKJDeAHwAQH4Af4JgALQBYoCDAgAEAEYZCBlKFQwDw==&rs=AOn4CLBCbKYAqsfo0JnB6phON2yK6E1c9Q',\n",
       "  'https://i.ytimg.com/vi/aVQQuoToTJA/hqdefault_1564666.jpg?sqp=-oaymwE9CNACELwBSFryq4qpAy8IARUAAAAAGAElAADIQj0AgKJDeAHwAQH4Af4JgALQBYoCDAgAEAEYZCBlKFQwDw==&rs=AOn4CLD7F4V0sr9RGHXsoUXZ-QBcw06Mew',\n",
       "  'https://i.ytimg.com/vi/aVQQuoToTJA/hqdefault_1670766.jpg?sqp=-oaymwE9CNACELwBSFryq4qpAy8IARUAAAAAGAElAADIQj0AgKJDeAHwAQH4Af4JgALQBYoCDAgAEAEYZCBlKFQwDw==&rs=AOn4CLDclDrxnt0Iytx0PGA-Xx6amrep6w',\n",
       "  'https://i.ytimg.com/vi/aVQQuoToTJA/hqdefault_2427133.jpg?sqp=-oaymwE9CNACELwBSFryq4qpAy8IARUAAAAAGAElAADIQj0AgKJDeAHwAQH4Af4JgALQBYoCDAgAEAEYZCBlKFQwDw==&rs=AOn4CLDaSuyOmeyhaIMLWCW1dH_DvtRr-w',\n",
       "  'https://i.ytimg.com/vi/aVQQuoToTJA/hqdefault_2667266.jpg?sqp=-oaymwE9CNACELwBSFryq4qpAy8IARUAAAAAGAElAADIQj0AgKJDeAHwAQH4Af4JgALQBYoCDAgAEAEYZCBlKFQwDw==&rs=AOn4CLCzh3RdS32Ru3q-bHVGJu31tchByA',\n",
       "  'https://i.ytimg.com/vi/aVQQuoToTJA/hqdefault_2921166.jpg?sqp=-oaymwE9CNACELwBSFryq4qpAy8IARUAAAAAGAElAADIQj0AgKJDeAHwAQH4Af4JgALQBYoCDAgAEAEYZCBlKFQwDw==&rs=AOn4CLBfWbUgJmuM_omg6HuRDw0hj_Qm6Q',\n",
       "  'https://i.ytimg.com/vi/aVQQuoToTJA/hqdefault_2964866.jpg?sqp=-oaymwE9CNACELwBSFryq4qpAy8IARUAAAAAGAElAADIQj0AgKJDeAHwAQH4Af4JgALQBYoCDAgAEAEYZCBlKFQwDw==&rs=AOn4CLCthj6Verux7gN4f3P9czDaJcXZPw',\n",
       "  'https://i.ytimg.com/vi/aVQQuoToTJA/hqdefault_2974833.jpg?sqp=-oaymwE9CNACELwBSFryq4qpAy8IARUAAAAAGAElAADIQj0AgKJDeAHwAQH4Af4JgALQBYoCDAgAEAEYZCBlKFQwDw==&rs=AOn4CLCraMUcWgk_XiGCv69bE5xMS47Scw',\n",
       "  'https://i.ytimg.com/vi/aVQQuoToTJA/hqdefault_3081000.jpg?sqp=-oaymwE9CNACELwBSFryq4qpAy8IARUAAAAAGAElAADIQj0AgKJDeAHwAQH4Af4JgALQBYoCDAgAEAEYZCBlKFQwDw==&rs=AOn4CLCKXglKy0S00-fpV39qWJjppYnFGQ'])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapters_and_time_and_images(video_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcripts(video_code: str) -> List[str]:\n",
    "    \n",
    "    start: List = []\n",
    "    text: List = []\n",
    "\n",
    "    # Get the start time and text of closed captions from transcript API \n",
    "    trans = YouTubeTranscriptApi.get_transcript(video_code)\n",
    "    for content in trans:\n",
    "        start.append(content['start'])\n",
    "        text.append(content['text'])\n",
    "\n",
    "    return start, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lt(a, x):\n",
    "    'Find rightmost value less than x'\n",
    "    if x == '00:00:00' or x == 0:\n",
    "        return 0\n",
    "    i = bisect.bisect_left(a, x)\n",
    "    if i:\n",
    "        if a[i] == x:\n",
    "            return i\n",
    "        else:\n",
    "            return i-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters, start_time_api, images_url = chapters_and_time_and_images(video_code)\n",
    "start, text = get_transcripts(video_code)\n",
    "\n",
    "indexes: List = []\n",
    "for j in start_time_api:\n",
    "    indexes.append(find_lt(start, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42, 134, 246, 296, 660, 717, 1043, 1165, 1276, 1284, 1298, 1342]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ , modified_text = get_transcripts(video_code)\n",
    "\n",
    "counter = -1\n",
    "modified_text.insert(-1, \"\\n\\n\\n\")\n",
    "for i in indexes[::-1]:\n",
    "\n",
    "    if i == 0:\n",
    "        modified_text.insert(0, \"\\n\\n\")\n",
    "        modified_text.insert(0, chapters[0])\n",
    "    else:\n",
    "        modified_text.insert(i-1, \"\\n\\n\")\n",
    "        modified_text.insert(i-1, chapters[counter])\n",
    "        modified_text.insert(i-1, \"\\n\\n\\n\")\n",
    "        counter -= 1\n",
    "\n",
    "\n",
    "with open(\"tmp2.txt\", \"w+\") as file:\n",
    "     file.write(\" \".join(modified_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "data = requests.get('https://i.ytimg.com/vi/aVQQuoToTJA/hqdefault_114433.jpg?sqp=-oaymwE9CNACELwBSFryq4qpAy8IARUAAAAAGAElAADIQj0AgKJDeAHwAQH4Af4JgALQBYoCDAgAEAEYZCBlKFQwDw==&rs=AOn4CLAWsuPZH7ETroeyS2k9HtBAn3XRpA').content\n",
    "  \n",
    "with open('img.jpg','wb') as f:\n",
    "    f.write(data)\n",
    "img = Image.open('img.jpg')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a youtube transcript punctuator. Given a youtube transcript, you should add all the punctuations wherever necessary without losing the context.\n",
      "Below is the transcript from a youtube video.\n",
      "Punctuate it and give it back in html format.\n",
      "\n",
      "The first line is the title. Add two new lines after the heading and make the title bold and then punctuate it.\n",
      "\n",
      "hi everyone it's my pleasure and today to introduce Eustis Eustis is a postdoc at the baker Lab at the University of Washington he obtained his bachelor's and Master's in mathematics and his PhD in biophysics all from the University of Cambridge today Eustis will talk about his work on protein mpnn I'm sure all of us have seen the work recently come out and in science and we're all very excited to uh to hear what you've got for us so I think we're going to keep questions uh for the end but feel free to to put them in the chat in the meantime take it away you sis uh thank you for the introduction um so I'll be presenting on party MPN and please note down the questions and then ask them at the end so first of all I'd like to thank all protein MPN team so there's lots of people who've been working on it some both creating database training models and also doing experimental work and usually when I present the work I go into the details how the project started and present all the sort of like nasty bits but I'm just going to reverse and explain what is part of the MPN and present experimental data first and then we will dive into some of the metrics so the protein mpnn is the model to map protein backbone geometry into protein sequences uh so this structured a sequence and sequence of structure mapping and we all know sort of alpha Falls and Rec centerfold predicting from a sequence structure so some of the experimental results one\n",
      "<h1><strong>Hi Everyone! It's My Pleasure</strong></h1>\n",
      "\n",
      "<p>Today, I am here to introduce Eustis. Eustis is a postdoc at the Baker Lab at the University of Washington. He obtained his bachelor's and Master's in mathematics and his PhD in biophysics, all from the University of Cambridge. Today, Eustis will talk about his work on protein MPNN. I'm sure all of us have seen the work recently come out and in science, and we're all very excited to hear what you've got for us. So, I think we're going to keep questions for the end, but feel free to put them in the chat. In the meantime, take it away, Eustis. Thank you for the introduction.</p>\n",
      "\n",
      "<p>So, I'll be presenting on party MPN, and please note down the questions and then ask them at the end. First of all, I'd like to thank all protein MPN team. So, there are lots of people who've been working on it, some both creating database training models and also doing experimental work. Usually, when I present the work, I go into the details of how the project started and present all the sort of like nasty bits, but I'm just going to reverse and explain what is part of the MPN and present experimental data first, and then we will dive into some of the metrics.</p>\n",
      "\n",
      "<p>The protein MPNN is the model to map protein backbone geometry into protein sequences. So, this structured a sequence and sequence of structure mapping, and we all know sort of alpha Falls and Rec centerfold predicting from a sequence structure. So, some of the experimental results one.</p>\n",
      "You are a youtube transcript punctuator. Given a youtube transcript, you should add all the punctuations wherever necessary without losing the context.\n",
      "Below is the transcript from a youtube video.\n",
      "Punctuate it and give it back in html format.\n",
      "\n",
      "The first line is the title. Add two new lines after the heading and make the title bold and then punctuate it.\n",
      "\n",
      "Hallucinating Symmetric Protein Assemblies \n",
      "\n",
      " of the papers that came out at the same time were partly mpnn is called hallucinating symmetric protein assemblies and in this case this is a figure from the paper the so Lucas puzzle and Alexi in our lab they've been playing with hallucinating or creating generating proteins using Alpha fold so in this case with the interest in it cyclic proteins so in this for example three copies of the protein of the exactly the same sequence I introduced initially and then we can use R4 to predict the structure and impose some losses so for example ask the model to be very um very certain so high pldt and PTM but also introduced a cycling loss and then do Markov chain Monte Carlo mcmc to try to mutate some sequences and keep doing this Loop until we get really the metrics like we want the and then at the end I will show that these designs need to be redesigned with 14 npn and some sort of model that Maps structure the sequence because the original design did not work and if we look at the sort of the solubility so the how much soluble yield there was from different designs so this original Markov chain Monte Carlo hallucination for these homologous those who have the solubility results on guest median is about 10 milligrams per liter but then so a bunch of them are really low yields so they sort of say insoluble proteins they aggregated redesigned the same exact backbone supporting the impended and increase the soluble yield quite a lot this is a log scale so now we're talking about hundreds even close to thousands of um of milligrams per liter um also from these uh oligomeric designs they we got Crystal structures so this is showing seven Crystal structures some of the homo dimers and uh trimers and so on and the gray are the models and the salt structures are colored and there's some interesting designs the beta sheets and Alpha helices wrapping around so that's quite exciting and they all match quite well the design structures um I guess I should say that all of these were so I'll probably mention before later but the redesign sequence of Courtney and pin and again we predicted by Alpha fold to make sure that there's a match between what we try to design and what we redesigned reporting in pnn also we can hallucinate these like large structures so these different rings of different symmetries of c18 6 so there's a six units and there's internal symmetry of 18 and this showing at chromium a negative stain microscopy results so that's quite exciting there's lots of big structures and our show property and pnm you can redesign these symmetric proteins making sure that the sequence stays symmetric um in the in the in the I guess in the uh Institute for protein design we also have the Kings lab they're working on different nanoparticles so in this case uh Robert de Haas redesigned some of the tetrahedral nanoparticles so in this case the original design was then the Rosetta uh class design and the interface was not forming this particle was not forming together but then redesigned the party and K N quite similar backbones that fail initially from earlier papers now give really nice Crystal structures that match and these particles are really stable so that's quite exciting um\n",
      "<h1><strong>Hallucinating Symmetric Protein Assemblies</strong></h1>\n",
      "\n",
      "<p>Of the papers that came out at the same time, were partly mpnn is called hallucinating symmetric protein assemblies and in this case this is a figure from the paper the so Lucas puzzle and Alexi in our lab they've been playing with hallucinating or creating generating proteins using Alpha fold so in this case with the interest in it cyclic proteins so in this for example three copies of the protein of the exactly the same sequence. I introduced initially and then we can use R4 to predict the structure and impose some losses so for example ask the model to be very um very certain so high pldt and PTM but also introduced a cycling loss and then do Markov chain Monte Carlo mcmc to try to mutate some sequences and keep doing this Loop until we get really the metrics like we want the and then at the end I will show that these designs need to be redesigned with 14 npn and some sort of model that Maps structure the sequence because the original design did not work and if we look at the sort of the solubility so the how much soluble yield there was from different designs so this original Markov chain Monte Carlo hallucination for these homologous those who have the solubility results on guest median is about 10 milligrams per liter but then so a bunch of them are really low yields so they sort of say insoluble proteins they aggregated redesigned the same exact backbone supporting the impended and increase the soluble yield quite a lot this is a log scale so now we're talking about hundreds even close to thousands of um of milligrams per liter um also from these uh oligomeric designs they we got Crystal structures so this is showing seven Crystal structures some of the homo dimers and uh trimers and so on and the gray are the models and the salt structures are colored and there's some interesting designs the beta sheets and Alpha helices wrapping around so that's quite exciting and they all match quite well the design structures um I guess I should say that all of these were so I'll probably mention before later but the redesign sequence of Courtney and pin and again we predicted by Alpha fold to make sure that there's a match between what we try to design and what we redesigned reporting in pnn also we can hallucinate these like large structures so these different rings of different symmetries of c18 6 so there's a six units and there's internal symmetry of 18 and this showing at chromium a negative stain microscopy results so that's quite exciting there's lots of big structures and our show property and pnm you can redesign these symmetric proteins making sure that the sequence stays symmetric um in the in the in the I guess in the uh Institute for protein design we also have the Kings lab they're working on different nanoparticles so in this case uh Robert de Haas redesigned some of the tetrahedral nanoparticles so in this case the original design was then the Rosetta uh class design and the interface was not forming this particle was not forming together but then redesigned the party and K N quite similar backbones that fail initially from earlier papers now give really nice Crystal structures that match and these particles are really stable so that's quite exciting um</p>\n",
      "You are a youtube transcript punctuator. Given a youtube transcript, you should add all the punctuations wherever necessary without losing the context.\n",
      "Below is the transcript from a youtube video.\n",
      "Punctuate it and give it back in html format.\n",
      "\n",
      "The first line is the title. Add two new lines after the heading and make the title bold and then punctuate it.\n",
      "\n",
      "Incorporating these Short Linear Motives into Genova Design Protein Scaffolds \n",
      "\n",
      " one of the other examples is that who are they in our lab was trying to design incorporating these short linear motives into Genova design protein scaffolds so the idea is that for example if this sa issue domain is to bind this native peptide so we want to come up with the protein structure this de Nova small peptide that would support this green structure so originally it was designed with Rosetta remodel their design and packing but there was no binding signal but then redesigning the protein opinion whole uh this orange structure keeping the green structures the given native so trying to support it provided binding and then just to test whether some of these threads is actually supporting the structure they were modifications made from spark Gene to aspartate and it indeed was supporting this small green structure uh the more papers coming using coming out they're using that are using protein in pnm so this is one example from the uh from Nate Bennett it's called improving the neuroprotein design uh using deep learning so some of the some of the failure modes for Designing uh proteins is that if we're trying to design a binder for a Target sometimes the binder itself doesn't form so this type of one failure but sometimes also it doesn't bind so it's a sidewalk to failure and there's some examples sort of showing metrics in this case the metric is Alpha fold success of the predicted align error using different methods like Rosetta design protein and pnn and also people try to run protein and pnn and run fast relax to move the backbone a little bit and then run protein and pin and again and you can see that the third method of running approaching independent and fast relax in Cycles is increasing this Alpha false success rate at least sort of tricking alcohol to think that those are good binders and also in this paper there's some benchmarking results showing that the previous results Alpha fold prediction line error can be used to discriminate better binders from the worst binders another paper that you supporting the opinion is our lab is related to the conclusion hallucinating this symmetric oligomers but in this case think about creating proteins with pockets so these pockets would be used for binding different small molecules so the same idea of Designing these oligomers but then redesigning the protein and pen and removing the symmetry so allowing these three units to be of different sequence so the sequence would become different so they wouldn't be perfect homologous but they would have different genes but the they call it pseudo symmetric so the backbone is symmetric but the sequence is not symmetric um so it's always I guess fun to do a little demonstration so I'm gonna show this hugging face created by Simon and try to predict this um this top seven so this is the Nova design party in one qos this figure was made for the ipd so instantly property and design celebrating 10 years so we can try to redesign this sequence and then predict the buffer fold um so this is this is this hugging face setup there's also a GitHub code where it has maybe slightly more options how to make but this is a very simple setup so in this case we can either upload a pdb or write the uh write the code so one qis was the code and if we go to the settings we can choose which sequencer designs so this design there's only one chain a I'm sorry we'll let's say design for sequences which is the sampling temperature is to go small sampling temperature we can choose what sort of model you use and I'll talk about these different models train a different amount of noise so let's use the default and then we can just run the model and design sequences so it is quite fast that's it we we this is what this was the original sequence and then now we redesigned four sequences and the model outputs the temperature that were designed at uh what is the score so this is a negative log probability so lower the better than the sequencer probably what is the match between the output sequence and the input sequence what was the model name so we have about 40 45 sequence similarity from the input\n",
      "<h1><b>Incorporating these Short Linear Motives into Genova Design Protein Scaffolds</b></h1>\n",
      "\n",
      "\n",
      "One of the other examples is that who are they in our lab was trying to design incorporating these short linear motives into Genova design protein scaffolds. So, the idea is that for example if this sa issue domain is to bind this native peptide, so we want to come up with the protein structure this de Nova small peptide that would support this green structure. So, originally it was designed with Rosetta remodel their design and packing but there was no binding signal. But then redesigning the protein opinion whole uh this orange structure keeping the green structures the given native so trying to support it provided binding. And then just to test whether some of these threads is actually supporting the structure they were modifications made from spark Gene to aspartate and it indeed was supporting this small green structure. The more papers coming using coming out they're using that are using protein in pnm so this is one example from the uh from Nate Bennett it's called improving the neuroprotein design uh using deep learning. \n",
      "\n",
      "Some of the failure modes for Designing uh proteins is that if we're trying to design a binder for a Target sometimes the binder itself doesn't form so this type of one failure but sometimes also it doesn't bind so it's a sidewalk to failure and there's some examples sort of showing metrics in this case the metric is Alpha fold success of the predicted align error using different methods like Rosetta design protein and pnn and also people try to run protein and pnn and run fast relax to move the backbone a little bit and then run protein and pin and again and you can see that the third method of running approaching independent and fast relax in Cycles is increasing this Alpha false success rate at least sort of tricking alcohol to think that those are good binders and also in this paper there's some benchmarking results showing that the previous results Alpha fold prediction line error can be used to discriminate better binders from the worst binders another paper that you supporting the opinion is our lab is related to the conclusion hallucinating this symmetric oligomers but in this case think about creating proteins with pockets so these pockets would be used for binding different small molecules so the same idea of Designing these oligomers but then redesigning the protein and pen and removing the symmetry so allowing these three units to be of different sequence so the sequence would become different so they wouldn't be perfect homologous but they would have different genes but the they call it pseudo symmetric so the backbone is symmetric but the sequence is not symmetric um so it's always I guess fun to do a little demonstration so I'm gonna show this hugging face created by Simon and try to predict this um this top seven so this is the Nova design party in one qos this figure was made for the ipd so instantly property and design celebrating 10 years so we can try to redesign this sequence and then predict the buffer fold um so this is this is this hugging face setup there's also a GitHub code where it has maybe slightly more options how to make but this is a very simple setup so in this case we can either upload a pdb or write the uh write the code so one qis was the code and if we go to the settings we can choose which sequencer designs so this design there's only one chain a I'm sorry we'll let's say design for sequences which is the sampling temperature is to go small sampling temperature we can choose what sort of model you use and I'll talk about these different models train a different amount of noise so let's use the default and then we can just run the model and design sequences so it is quite fast that's it we we this is what this was the original sequence and then now we redesigned four sequences and the model outputs the temperature that were designed at uh what is the score so this is a negative log probability so lower the better than the sequencer probably what is the match between the output sequence and the input sequence what was the model name so we have about 40 45 sequence similarity from the input.\n",
      "You are a youtube transcript punctuator. Given a youtube transcript, you should add all the punctuations wherever necessary without losing the context.\n",
      "Below is the transcript from a youtube video.\n",
      "Punctuate it and give it back in html format.\n",
      "\n",
      "The first line is the title. Add two new lines after the heading and make the title bold and then punctuate it.\n",
      "\n",
      "Structural Addition \n",
      "\n",
      " native crystal structure to the design sequences and now we can do structural addition so we're going to run Alpha fold three recycles on all of the sequences and it's going to take about 30 seconds so I'll go back to this later to see what are the what is the match between the input and the outputs um so if we continue I'll share my slide one second [Music] okay so while this prediction is running I'm going to continue the describing the model so we have a structure the sequence model and some of the analogies that often people think in protein machine learning are these sort of I guess computer related image image generation or text so in this case I'm sort of showing the this task of mapping from protein backbone into the sequence and then from the sequencer to the backbone is an analogy between mapping an image describing it as in a caption so in this case this is a small cactus wearing a straw hat and a neon sunglasses in the Sahara Desert and then using the text to generate the image so in this case this image was generated by Imogen giving this text prompt and generating the image so this is sort of like a generator model that will produce many many solutions in this case this protein name pianon is more like mapping a image into the text but the distributions are quite different in this case it's a 2d go to pixels in probably in a protein world it's 3D coordinate of the atoms and from this sort of like a translation perspective the number of residues are matching in the coordinates and also in the residue so we have a matching lens and there's only 20 layers available so somewhat simpler maybe task the task for prediction structure is quite difficult and it requires homology and other\n",
      "<h1><b>Structural Addition</b></h1>\n",
      "\n",
      "\n",
      "<p>Native crystal structure to the design sequences and now we can do structural addition. So, we're going to run Alpha fold three recycles on all of the sequences and it's going to take about 30 seconds. So, I'll go back to this later to see what are the what is the match between the input and the outputs. Um, so if we continue I'll share my slide one second. <span>[Music]</span></p>\n",
      "\n",
      "<p>Okay, so while this prediction is running, I'm going to continue the describing the model. So, we have a structure, the sequence model, and some of the analogies that often people think in protein machine learning are these sort of I guess computer related image image generation or text. So, in this case, I'm sort of showing the this task of mapping from protein backbone into the sequence and then from the sequencer to the backbone is an analogy between mapping an image describing it as in a caption. So, in this case, this is a small cactus wearing a straw hat and a neon sunglasses in the Sahara Desert and then using the text to generate the image. So, in this case, this image was generated by Imogen giving this text prompt and generating the image. So, this is sort of like a generator model that will produce many many solutions. In this case, this protein name pianon is more like mapping an image into the text but the distributions are quite different. In this case, it's a 2d go to pixels in probably in a protein world it's 3D coordinate of the atoms and from this sort of like a translation perspective the number of residues are matching in the coordinates and also in the residue. So, we have a matching lens and there's only 20 layers available so somewhat simpler maybe task the task for prediction structure is quite difficult and it requires homology and other.</p>\n",
      "You are a youtube transcript punctuator. Given a youtube transcript, you should add all the punctuations wherever necessary without losing the context.\n",
      "Below is the transcript from a youtube video.\n",
      "Punctuate it and give it back in html format.\n",
      "\n",
      "The first line is the title. Add two new lines after the heading and make the title bold and then punctuate it.\n",
      "\n",
      "Problem Statement \n",
      "\n",
      " information uh so the problem statement what sort of was the idea behind protein MPN is to come up to the model that can sample sequences that are highly likely we could model multiple trains we could fix parts of the chain and we provide uncertainty about the samples so in this case this could be an example of two chains one chain here and one chain here and we want to maybe fix everything and just redesign the interface so just redesigned the red Parts giving all the rest and the model we'd like to Output the sequence and also the probabilities of the sequence experience that when you gave I the one at 9am was 42 and then you added more so the examples would be one-sided binded design uh homologous design enzyme design and so on uh the training data was collected by Yvonne and schenko so it's a similar training data for I guess uh Rosetta fold but in this case we're using the pdb bi-units so these biomets we collect a single chance of ppdb costed at 30 C plus identity we're using three and a half anxon resolution cut off and taking the complexes that are smaller than 10 000 rescues and so in the training data set there would be a bunch of homo dimers uh homo ligamers and the we are asking for the model to only predict one single chain that we clustered in the context of everything else so it would be a very simple task if we ask for example given the blue chain that's exactly matching the right chain to predict the sequence that would be the model can just copy over so what do we do we check the sequence similarity to see if it's more than 70 similar to the from Two Chains and if they are then the model has to predict res sequence of all the chains instead of only one chain so preventing this data leakage from the homolog American similar sequences and the objective for the model is to minimize the caloric per centropy so the this P distribution is the original distribution so in this case for example it's a glutamate so it's a probability of one this is an initial distribution and the model is outputting a distribution q that would be some distribution that the model thinks it is and then we'll just compute the the log probability of the correct amino acids of glutamate and send them over so in this case the model is using Auto aggressive decomposition so for example given a small bit of the sequence that was already decoded and the backbone the model produces the probabilities of the amino acids and then we sample from this distribution to get to get a sample so in this case it's sampling e and then using this information we predict again a new probability distribution for the next amino acid and then again samples so in this case it's Proline so the model is multi-step or Auto regressive is decomposed that one amino acid at a time it is predicting distributions and then we sample from these distributions uh so just comparing this left to right decoding that is more common in a language translation and probably an opinion was using arbitrary decoding so doing training and doing training a random decoding order was given and the model had to learn all the different decoding orders so in this case for Left Right decoding we have some text that's on the left and we just predict the next as a function of everything on the left in the arbitable decoding we can for example still wanted to code these two amino acids the model can use both the context on the left and on the right whereas the left radical would not be able to use for example these three letters to the right the input features to the model so talking about these geometric features are first of all we sort of assume that the local context will be the most important so we're forming these local neighborhoods what we raised you in terms of DC Alpha sulfur distance and then the input features for to tell that residue I and J are for example in different chains so the green uh green nodes or these circles are chain a the red one is chain B so we would give the plus 32 plus minus 32 in the primary sequence so example this residue would know it's one residue to the left of this other residue or two residues to the left of the this residue if the residues are in a different chains then we just give a sort of binary indicator say that these residues are in different units so this is similar to the alpha fold uh encoding of the positional encoding but plus also taking care that there's no it doesn't matter what the chain a is called a or called B so that there's no egg a goes before B so it's just the indication what is the same chain of different chains and then on the edges we also have the distances so we have this radial basis functions I'm not sure what they are for distances between backbone atoms so ncl2c and oxygen and there's also a virtual C beta that is calculated as a function of the other residues to get to test whether this Assumption of the local neighborhood is correct we can train neural networks and to check sequence recovery as a function of the neighbors and the graph so this is for example using 16 areas neighbors 32 years neighbors 64 years neighbors and you can see that the performance of in terms of sequence recovery is uh converging it's not getting better if we make the graph uh more and more connected so it is mostly the local information that is important to predict amino acid identity so these distances or these input features are these 25 distance between nclfc and virtual C beta so in this case this is ncl4c oxygen and C beta so we have all the interdistances that are encoded it's like radial basis function so we can imagine this like little channels that are exponent exponential of the true distance minus this middle of the distances of these bins divided by some standard deviation so they go only from zero to one everything is very nicely normalized and if the distance is really big it will just get everything with zeros and if the distance is very small there'll be maybe a very small clip for the first bin we try to do all the different variations that have angles so using given the hero angles as an input relative frame angles and so on it really is does not work as well or doesn't add on top of the what the distances give so the distances are probably a better inductive bias maybe it's easier for the model to learn what's going on so just giving distances between all the params so things we have so far is we made this graph that is local graph and we have the features on the edges that are this positional encoding and also these geometric features and then we want to predict these probability distributions per node given the rest of the amino acid so amino acids will be encoded as nodes that some of them are decoded and then we have the true we can calculate the credible cross entropy laws since we have to run this model as many times as their amino acids it is useful to somehow discretize the model so basically you have a backbone encoder and a sequence decoder and that's very often done in the language transition to having an encoder and decoder so the encoder job will be to encode the backbone and that the decoder job will be to run iteratively multiple times to decode one amino acid at this time so let's dive in slightly deep a little bit deeper into the backbone encoder we're seeing takes this uh distances between different atoms as node features and then there are no no sh features and the no node features so the model is having these edges and nodes those are just initially zero so we can just unbe omitted and it's a message passing neural network that updates the nodes and then updates the edges to come up with better nodes and better edges that are the three layers of those that can be run and then the decoder takes the final encoded edges and nodes and also has the sequence into the nodes uh the one that was already decoded to produce probabilities from which can be sampled during training we're not sampling we're using teacher forcing to just run in one pass all the decoder but doing doing the inference we can sample one at a time and run decoder multiple times so the model architecture is really lightweight it's about 1.7 million parameters so just three decoder layers three encoders 3D code layers takening Dimension is 128 comparing with Alpha fold which has about 100 million parameters so this is a really cheap to run even on CPUs and can run on really big proteins like 10 000 of residue so more uh one of the important aspects in training these models is adding a backboard noise so since the crystal structures probably have some artifacts they're very uh especially the higher resolution ones and in when people are designing things we're really not sure about the backbone how does backbone exactly uh is positioned so we want to make the model that is not very sensitive to the input uh input coordinates there's some slack so we're adding gaussian noise in training to all the coordinates but then during the inference there's no need to add any noise because the model is already for example not paying attention to the scales of 0.2 angstroms so this is one of the benchmarks the whole idea for the paper was born from the John Ingram's paper journal to models for graph based partying design and we tried to build on top to see what could be improved so this is a table showing that if we take exactly the model from John Ingram's method and then we just change one thing at a time so this model is not going to exactly match the model that I just described here because in this case there were some dihedral feed the hedral input features and so on but if we take the Baseline model that is exactly in this paper and then we just change one thing at a time so experiment one is adding these distances as an input features we can see that the segments recovery straight away goes from 41 to 49 so there's definitely adding the inter distance feature was a really helpful inductive bias uh and then updating encoder edges in the normal sort of vanilla and pnn there's only no WS there's no Edge updates it's giving a small increase compared to the Baseline and then if we combine one and two we get a slightly higher boost and then if we this all the Baseline experiment one two three are all left to right decoding both aggressive models if we switch from the left to right to a random decoding order so the model has to learn all the possible detail in others there's no decrease in performance it is almost the same and one interesting thing to notice is that the this noise level of doing training is that the original models were run without any noise and we also test what would happen if we add a very small 0.02 angstrom side and deviation gaussian noise and you can see that the performance is on the pdb crystal structure is getting lower so even at the highest it's about three percent different so it means about three percent of the performance is coming from this really really tiny amount of distance that the model is either picking up on the crystals that maybe the distance between C Alpha and C Alpha is indicating that it's going to be specific amino acids but if we take off of all models that are idealized backbone the difference is much smaller or sometimes it's even better it sort of is better to train the model that is robust it's not overfitted to the crystal structure so that's an interesting uh observation all of the other results that I'll show will be for the model that is actually uh protein and pnn on the GitHub so this is the only one that is more like a toy example so comparing the Rosetta that's been mainly used in uh in a bigger lab I'm plotting the sequence recovery as a function of the average C beta distance so I wanted some measure that is independent of the side chain parking that would show how buried the residue is so we have a core residues that are in the core of the protein and then the surface residues and I'm showing the fraction of the residues that fall Within These distances for the nearest sibera and this is this virtual severe uh even if natom doesn't have C beta we'll calculate virtual C beta that on average there is for example 30 of residues at this 6.2 angstrom eight neighbor close the distance we see that pregnant is doing better than rosetta in both in the core and on the surface and they're both uh kind of matching at the core there's a really high certainty with almost 90 percent uh accuracy or sequence to copy the model can recover what was actually there and then on the surface it's much lower but they're both almost monotonic functions of this neuroscibility distance which is an interesting suggest that the the ability to recover the sequence is it's a function of the geometry it's saying how much of the constraints I have from other residues around this is not incorporating any function or any other things if we look at the protein by protein basis so one dot is one protein I think this is about 400 monomeric structures recovery is better than rosetta in most of the cases except this one point and there's definitely a correlation so this correlation is probably coming from intrinsically how how well packed the backbone is we could also look at the sequence recovery so the model was shown on complexes that has been trained on the homeowners heteromers and interfaces so we can plot out how it performs a sequence recovery for these different\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m new_prompt \u001b[39m=\u001b[39m prompt \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m chunk\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(new_prompt)\n\u001b[0;32m---> 15\u001b[0m response: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m llm(new_prompt)\n\u001b[1;32m     16\u001b[0m \u001b[39mprint\u001b[39m(response)\n\u001b[1;32m     17\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mstr\u001b[39m(counter)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/langchain/llms/base.py:246\u001b[0m, in \u001b[0;36mBaseLLM.__call__\u001b[0;34m(self, prompt, stop)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, prompt: \u001b[39mstr\u001b[39m, stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    245\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check Cache and run the LLM on the given prompt and input.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([prompt], stop\u001b[39m=\u001b[39;49mstop)\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/langchain/llms/base.py:140\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    141\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_end(output, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/langchain/llms/base.py:137\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    134\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, prompts, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose\n\u001b[1;32m    135\u001b[0m )\n\u001b[1;32m    136\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(prompts, stop\u001b[39m=\u001b[39;49mstop)\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/langchain/llms/openai.py:656\u001b[0m, in \u001b[0;36mOpenAIChat._generate\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[39mreturn\u001b[39;00m LLMResult(\n\u001b[1;32m    653\u001b[0m         generations\u001b[39m=\u001b[39m[[Generation(text\u001b[39m=\u001b[39mresponse)]],\n\u001b[1;32m    654\u001b[0m     )\n\u001b[1;32m    655\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 656\u001b[0m     full_response \u001b[39m=\u001b[39m completion_with_retry(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    657\u001b[0m     llm_output \u001b[39m=\u001b[39m {\n\u001b[1;32m    658\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtoken_usage\u001b[39m\u001b[39m\"\u001b[39m: full_response[\u001b[39m\"\u001b[39m\u001b[39musage\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    659\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name,\n\u001b[1;32m    660\u001b[0m     }\n\u001b[1;32m    661\u001b[0m     \u001b[39mreturn\u001b[39;00m LLMResult(\n\u001b[1;32m    662\u001b[0m         generations\u001b[39m=\u001b[39m[\n\u001b[1;32m    663\u001b[0m             [Generation(text\u001b[39m=\u001b[39mfull_response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m])]\n\u001b[1;32m    664\u001b[0m         ],\n\u001b[1;32m    665\u001b[0m         llm_output\u001b[39m=\u001b[39mllm_output,\n\u001b[1;32m    666\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/langchain/llms/openai.py:99\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     97\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 99\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/langchain/llms/openai.py:97\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 97\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/openai/api_requestor.py:216\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[1;32m    219\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    220\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    221\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    222\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    223\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[1;32m    226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/openai/api_requestor.py:516\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    514\u001b[0m     _thread_context\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m _make_session()\n\u001b[1;32m    515\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 516\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    517\u001b[0m         method,\n\u001b[1;32m    518\u001b[0m         abs_url,\n\u001b[1;32m    519\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    520\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    521\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    522\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    523\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[1;32m    525\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    526\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m         )\n\u001b[1;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mreadline(_MAXLINE \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1276\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1277\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model_name = \"gpt-3.5-turbo\", temperature = 0)\n",
    "idx = 0\n",
    "prompt: str = \"\"\"You are a youtube transcript punctuator. Given a youtube transcript, you should add all the punctuations wherever necessary without losing the context.\n",
    "Below is the transcript from a youtube video.\n",
    "Punctuate it and give it back in html format.\n",
    "\n",
    "The first line is the title. Add two new lines after the heading and make the title bold and then punctuate it.\"\"\"\n",
    "counter = 0\n",
    "for i in range(len(modified_text)):\n",
    "    if modified_text[i] == \"\\n\\n\\n\":\n",
    "        chunked_text = modified_text[idx:i]\n",
    "        chunk = \" \".join(chunked_text)\n",
    "        new_prompt = prompt + \"\\n\\n\" + chunk\n",
    "        print(new_prompt)\n",
    "        response: str = llm(new_prompt)\n",
    "        print(response)\n",
    "        with open(str(counter)+'.jpg','wb') as f:\n",
    "            f.write(data)\n",
    "        if 0 not in start_time_api:\n",
    "            with open(\"test_chapters_2.html\", \"a+\") as file:\n",
    "                file.write(f\"\\n\\n{response}\")\n",
    "                file.write(f\"\\n<a href=\\\"https://www.youtube.com/watch?v={video_code}&t={start[idx]}s\\\">{chunked_text[0]}</a>\\n\")\n",
    "        else:\n",
    "            data = requests.get(images_url[counter]).content\n",
    "            with open(\"test_chapters_2.html\", \"a+\") as file:\n",
    "                file.write(f\"\\n\\n{response}\")\n",
    "                file.write(f\"\\n<img src=\\\"{str(counter)+'.jpg'}\\\" alt=\\\"Not Applicable\\\" />\")\n",
    "                file.write(f\"\\n<a href=\\\"https://www.youtube.com/watch?v={video_code}&t={start[idx]}s\\\">{chunked_text[0]}</a>\\n\")\n",
    "                counter += 1\n",
    "        idx = i+1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a32bb54064f85011afade05059d15c1b5b99d41aa62645a74ba23a7fae51f560"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
