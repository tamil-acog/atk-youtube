

<h1><strong>Hi Everyone! It's My Pleasure</strong></h1>

<p>Today, I am here to introduce Eustis. Eustis is a postdoc at the Baker Lab at the University of Washington. He obtained his bachelor's and Master's in mathematics and his PhD in biophysics, all from the University of Cambridge. Today, Eustis will talk about his work on protein MPNN. I'm sure all of us have seen the work recently come out and in science, and we're all very excited to hear what you've got for us. So, I think we're going to keep questions for the end, but feel free to put them in the chat. In the meantime, take it away, Eustis. Thank you for the introduction.</p>

<p>So, I'll be presenting on party MPN, and please note down the questions and then ask them at the end. First of all, I'd like to thank all protein MPN team. So, there are lots of people who've been working on it, some both creating database training models and also doing experimental work. Usually, when I present the work, I go into the details of how the project started and present all the sort of like nasty bits, but I'm just going to reverse and explain what is part of the MPN and present experimental data first, and then we will dive into some of the metrics.</p>

<p>The protein MPNN is the model to map protein backbone geometry into protein sequences. So, this structured a sequence and sequence of structure mapping, and we all know sort of alpha Falls and Rec centerfold predicting from a sequence structure. So, some of the experimental results one.</p>
<a href="https://www.youtube.com/watch?v=aVQQuoToTJA&t=4.38s">hi everyone it's my pleasure and today</a>


<h1><strong>Hallucinating Symmetric Protein Assemblies</strong></h1>

<p>Of the papers that came out at the same time, were partly mpnn is called hallucinating symmetric protein assemblies and in this case this is a figure from the paper the so Lucas puzzle and Alexi in our lab they've been playing with hallucinating or creating generating proteins using Alpha fold so in this case with the interest in it cyclic proteins so in this for example three copies of the protein of the exactly the same sequence. I introduced initially and then we can use R4 to predict the structure and impose some losses so for example ask the model to be very um very certain so high pldt and PTM but also introduced a cycling loss and then do Markov chain Monte Carlo mcmc to try to mutate some sequences and keep doing this Loop until we get really the metrics like we want the and then at the end I will show that these designs need to be redesigned with 14 npn and some sort of model that Maps structure the sequence because the original design did not work and if we look at the sort of the solubility so the how much soluble yield there was from different designs so this original Markov chain Monte Carlo hallucination for these homologous those who have the solubility results on guest median is about 10 milligrams per liter but then so a bunch of them are really low yields so they sort of say insoluble proteins they aggregated redesigned the same exact backbone supporting the impended and increase the soluble yield quite a lot this is a log scale so now we're talking about hundreds even close to thousands of um of milligrams per liter um also from these uh oligomeric designs they we got Crystal structures so this is showing seven Crystal structures some of the homo dimers and uh trimers and so on and the gray are the models and the salt structures are colored and there's some interesting designs the beta sheets and Alpha helices wrapping around so that's quite exciting and they all match quite well the design structures um I guess I should say that all of these were so I'll probably mention before later but the redesign sequence of Courtney and pin and again we predicted by Alpha fold to make sure that there's a match between what we try to design and what we redesigned reporting in pnn also we can hallucinate these like large structures so these different rings of different symmetries of c18 6 so there's a six units and there's internal symmetry of 18 and this showing at chromium a negative stain microscopy results so that's quite exciting there's lots of big structures and our show property and pnm you can redesign these symmetric proteins making sure that the sequence stays symmetric um in the in the in the I guess in the uh Institute for protein design we also have the Kings lab they're working on different nanoparticles so in this case uh Robert de Haas redesigned some of the tetrahedral nanoparticles so in this case the original design was then the Rosetta uh class design and the interface was not forming this particle was not forming together but then redesigned the party and K N quite similar backbones that fail initially from earlier papers now give really nice Crystal structures that match and these particles are really stable so that's quite exciting um</p>
<a href="https://www.youtube.com/watch?v=aVQQuoToTJA&t=106.439s">Hallucinating Symmetric Protein Assemblies</a>


<h1><b>Incorporating these Short Linear Motives into Genova Design Protein Scaffolds</b></h1>


One of the other examples is that who are they in our lab was trying to design incorporating these short linear motives into Genova design protein scaffolds. So, the idea is that for example if this sa issue domain is to bind this native peptide, so we want to come up with the protein structure this de Nova small peptide that would support this green structure. So, originally it was designed with Rosetta remodel their design and packing but there was no binding signal. But then redesigning the protein opinion whole uh this orange structure keeping the green structures the given native so trying to support it provided binding. And then just to test whether some of these threads is actually supporting the structure they were modifications made from spark Gene to aspartate and it indeed was supporting this small green structure. The more papers coming using coming out they're using that are using protein in pnm so this is one example from the uh from Nate Bennett it's called improving the neuroprotein design uh using deep learning. 

Some of the failure modes for Designing uh proteins is that if we're trying to design a binder for a Target sometimes the binder itself doesn't form so this type of one failure but sometimes also it doesn't bind so it's a sidewalk to failure and there's some examples sort of showing metrics in this case the metric is Alpha fold success of the predicted align error using different methods like Rosetta design protein and pnn and also people try to run protein and pnn and run fast relax to move the backbone a little bit and then run protein and pin and again and you can see that the third method of running approaching independent and fast relax in Cycles is increasing this Alpha false success rate at least sort of tricking alcohol to think that those are good binders and also in this paper there's some benchmarking results showing that the previous results Alpha fold prediction line error can be used to discriminate better binders from the worst binders another paper that you supporting the opinion is our lab is related to the conclusion hallucinating this symmetric oligomers but in this case think about creating proteins with pockets so these pockets would be used for binding different small molecules so the same idea of Designing these oligomers but then redesigning the protein and pen and removing the symmetry so allowing these three units to be of different sequence so the sequence would become different so they wouldn't be perfect homologous but they would have different genes but the they call it pseudo symmetric so the backbone is symmetric but the sequence is not symmetric um so it's always I guess fun to do a little demonstration so I'm gonna show this hugging face created by Simon and try to predict this um this top seven so this is the Nova design party in one qos this figure was made for the ipd so instantly property and design celebrating 10 years so we can try to redesign this sequence and then predict the buffer fold um so this is this is this hugging face setup there's also a GitHub code where it has maybe slightly more options how to make but this is a very simple setup so in this case we can either upload a pdb or write the uh write the code so one qis was the code and if we go to the settings we can choose which sequencer designs so this design there's only one chain a I'm sorry we'll let's say design for sequences which is the sampling temperature is to go small sampling temperature we can choose what sort of model you use and I'll talk about these different models train a different amount of noise so let's use the default and then we can just run the model and design sequences so it is quite fast that's it we we this is what this was the original sequence and then now we redesigned four sequences and the model outputs the temperature that were designed at uh what is the score so this is a negative log probability so lower the better than the sequencer probably what is the match between the output sequence and the input sequence what was the model name so we have about 40 45 sequence similarity from the input.
<a href="https://www.youtube.com/watch?v=aVQQuoToTJA&t=341.58s">Incorporating these Short Linear Motives into Genova Design Protein Scaffolds</a>


<h1><b>Structural Addition</b></h1>


<p>Native crystal structure to the design sequences and now we can do structural addition. So, we're going to run Alpha fold three recycles on all of the sequences and it's going to take about 30 seconds. So, I'll go back to this later to see what are the what is the match between the input and the outputs. Um, so if we continue I'll share my slide one second. <span>[Music]</span></p>

<p>Okay, so while this prediction is running, I'm going to continue the describing the model. So, we have a structure, the sequence model, and some of the analogies that often people think in protein machine learning are these sort of I guess computer related image image generation or text. So, in this case, I'm sort of showing the this task of mapping from protein backbone into the sequence and then from the sequencer to the backbone is an analogy between mapping an image describing it as in a caption. So, in this case, this is a small cactus wearing a straw hat and a neon sunglasses in the Sahara Desert and then using the text to generate the image. So, in this case, this image was generated by Imogen giving this text prompt and generating the image. So, this is sort of like a generator model that will produce many many solutions. In this case, this protein name pianon is more like mapping an image into the text but the distributions are quite different. In this case, it's a 2d go to pixels in probably in a protein world it's 3D coordinate of the atoms and from this sort of like a translation perspective the number of residues are matching in the coordinates and also in the residue. So, we have a matching lens and there's only 20 layers available so somewhat simpler maybe task the task for prediction structure is quite difficult and it requires homology and other.</p>
<a href="https://www.youtube.com/watch?v=aVQQuoToTJA&t=605.519s">Structural Addition</a>
