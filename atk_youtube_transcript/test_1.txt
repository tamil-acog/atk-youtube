

[INTRO]

I just want to tell you something up front, which is: I started using Mathematica 2.2 in 1994, and I was blown away. I thought it was awesome. I was using it as an undergraduate, and by about 2000 or so, it had gotten so good at doing integrals that I had this uh rule of thumb that was: if Mathematica couldn't do it, I can't, unless I had a library in probably hours and a lot of luck. So, yes, no, I think it's past humans. It cost humans a while ago.

Welcome back to MLST. So, in an era of technology and innovation, few individuals have left as indelible a mark on the fabric of modern science as our esteemed guest, Dr. Stephen Wolfram.

Dr. Wolfram is a renowned polymath who has left significant contributions to the fields of physics, computer science, and mathematics. A prodigious young man too, Wolfram earned a PhD in theoretical physics from the California Institute of Technology by the age of 20, and he became the youngest recipient of the prestigious MacArthur fellowship at the age of 21.

Wolfram's groundbreaking computational tool, Mathematica, was launched in 1988 and has become a cornerstone for researchers and innovators worldwide. And in 2002, he published A New Kind of Science, a paradigm-shifting work which explored the foundations of science through the lens of computational systems.

In 2009, Wolfram created Wolfram Alpha, a computational knowledge engine utilized by millions of users worldwide. And his current focus is on the Wolfram language, which is a powerful programming language designed to democratize access to cutting-edge technology.

Wolfram's numerous accolades include honorary doctorates and fellowships from prestigious institutions. And as an influential thinker, Dr. Wolfram has dedicated his life to unraveling the mysteries of the universe and making computation accessible to all.

As a trailblazer in the world of science and technology, Dr. Wolfram has dedicated his life to unraveling the mysteries of the universe and placing the power of computation in the hands of the masses.

So, we invite you to join us on this captivating journey through the mind of one of the most influential thinkers of our time. And Dr. Wolfram has just dropped a new book on chat GPT, which I had the pleasure of reading earlier, and I highly recommend you buy it. And, uh, actually, even more exciting than that, we've got the scoop on this: Dr. Wolfram has just announced an integration with chat GPT. There's now a plugins feature, and you can interrogate Wolfram Alpha from ChatGPT. But we'll get on to that in just a second. But just to finish the introduction, sit back, folks, relax, prepare to have your curiosity peaked, and your horizons broadened as we embark on this adventure into the extraordinary.

two worlds and I think it's going to be really interesting to see what happens as a result.

---

Big announcement! Wolfram + ChatGPT! 

Realm of Dr Stephen Wolfram 

Dr Wolfram, welcome to MLST. 

Thank you. Um, why don't we start with the most exciting bit, which is this big announcement? Why don't you tell us about that first? 

Yeah, well, as of today, Chat GPT can sort of get computational superpowers by calling on Wolfram Alpha and Wolfram Language through its plug-in mechanism. And, uh, the, you know, Chat GPT is a large language model which has kind of gone through the web and lots of books and so on, and it is piecing together things by sort of seeing what a reasonable piece of continuing text would be. And it's amazing how far that gets, and we'll, we'll perhaps talk a little bit later about why I think it gets as far as it does. But the thing it isn't able to do is actually do sort of serious computation. It is just saying, let me continue this text based on things that I've seen on the web and things that sort of seem reasonable based on the structure of language as humans have written it. But when it comes to actually computing things, that's just not something a neural net like it does. 

But we've been building for a long time now, uh, Wolfram Language. What's talk about that probably a bunch later, our sort of computational language to represent the world in a sort of precise computational way. And Wolfram Alpha, the kind of consumer version of that, that takes natural language input, converts that to Wolfram Language, to precise computational language, and then does computations. And very conveniently, Chat GPT, in a sense, talks natural language too. So that provides a kind of immediate bridge through the Wolfram Alpha natural language understanding system so that Chat GPT, when it wants to actually do a serious computation, can now reach out through Wolfram Alpha or directly to Wolfram Language, to our whole technology stack, to get those computations done. And obviously, another piece of what we've done is to get sort of computable curated data about the world and sort of implement the models and methods and algorithms and so on that are needed to compute expert-level answers to things. And so now, Chat GPT has access to all of those kinds of tools. 

I think it's kind of an exciting moment in kind of a merger of two different sort of approaches to kind of the problem of AI, the sort of statistical approach of just sort of see what's out there and kind of learn from that, and the kind of symbolic approach of see what you can actually compute. I would say that the things we've done, I don't haven't really viewed as being quote AI as such, it's more the deeper story of computation, but now we've got this kind of merger of these two worlds, and I think it's going to be really interesting to see what happens as a result.

What does it mean to understand?

Two approaches, uh, that just released about an hour ago now. Yeah, it's amazing. I don't think anyone would have seen this coming even five years ago when language models started coming onto the scene, that they might be used as a tool to take a natural language intelligible input and transform it into a representation that can be used on a downstream system. It's absolutely amazing, but why don't we go on a bit of an intellectual journey because I was very interested reading reading your book and I wondered whether you could um, we'll just start with how the language models work and kind of build from there philosophically and I mean philosophically and deeply because our audience are actually experts on on deep learning. I wondered if you could talk about how language models work from from your kind of abstract deep understanding, what the reasons are for their success and um, you said in the book that computing the probability of even 10 tuples of language would require more data than there are atoms in the universe, um, which is very interesting. So language models are clearly doing some kind of clever interpolation and most importantly, the thing that I'm very interested in is what does it mean to understand? Do you think there are language encodes enough representational fidelity to afford a useful semantic mapping to grounded reality or, you know, to what most people would understand in the world? And I'm sure you're aware of two major strands of thought in the philosophy of meaning, which is to say meaning as reference and meaning as use. So perhaps you could bring that into your answer as well.

Well, okay, so what does it mean to understand something? One of the things when we built Wolf Malfur in 2009, people have been trying to make, you know, natural language understanding systems for a long time. The problem that they always had, which I didn't realize until after the fact, I have to say, was that it wasn't clear what to understand actually means. You have this computer, it's doing it what it's doing, but what does it mean to understand? Well, we had a very definite definition of understanding. It was take the natural language and convert it to our computational language from which a computation can be done. We had a target for understanding. We had something which was kind of the ultimate representation from which we could do all these things with computation and so on, and that was our operational definition of understanding. Now, when you ask a question like I think it becomes a much muddier question when you say what does a language model understand? For me, sort of the gold standard of understanding is you can convert it to a computational language, you can compute all sorts of things about it, you can figure out from it anything that can be figured out from that sort of thing that is represented in this precise ways computational language. I think the thing that I've sort of realized, uh, so I've been interested in a long for a long time and kind of how do you represent things in the world in a sort of formal computational way, that's been the whole story of building, uh, wasn't language computational language, but the I've also been sort of interested, I've been curious for a long time how do you take kind of everyday discourse and convert it also to something computational, you know, in our in modern language, for example, if, well, let's say I say I want to eat a piece of chocolate. Okay, in modern language, we have a lovely representation of pieces of chocolate. We know about all kinds of different kinds of chocolate. We can characterize the size, etc., etc., etc. We haven't had a characterization of the I want to eat part of that sentence, but it is something I've long thought should be possible to represent in a kind of formal computational way. I think what chat GPT is showing us is that yes, it really is possible to think about language and kind of a and the things we represent by language in a quite structured way. So I mean the way I like to see it is what what charging PT has discovered regularities in language. So first first thing just to comment on this question of you know when it wants to make a continuation of a piece of text, you know, if it's just if it's just a single word, it might be able to go out on the web and just look at the Corpus and figure out the probability based on other occurrences of the previous words, but by the time as you were mentioning by the time it's any substantial number of words, there's no way it can have sort of you know statistical data to just work out the probability from that. So it has to have a model and one thing that's really interesting about neural Nets is when you have a model, there are there's no Obvious definition of a right answer, you know, it could be there could be but the our operational definition of a right answer is it sounds right to a human. So the thing that's really interesting about neural Nets is they do this modeling, they do this continuation, they do this extension beyond the merely statistical so to speak by in a way that corresponds to what we humans expect. Perhaps that isn't surprising because neural Nets are architecturally quite similar to brains and you know neural Nets as they exist in chat gbt are remarkably similar to the kind of original idealization invented by McCulloch and Pitts in the 1940s, but they're kind of the fact that what the continuation the particular model that Chachi BT or a neural net is using is something that corresponds to what we humans expect that's the thing that's interesting. You know if we were to imagine the aliens or the octopuses or whatever else it's not obvious that the thing that would be a reasonable continuation for us would also be a reasonable continuation for them, but that's a feature that happens to exist that we've discovered exists for these idealized neural Nets that we use in things like chat GPT. Now the question then is well what you know when we see sort of uh what did it discover about language that allows it to make that model what what's in that model it could be the case that that model is just something that we humans will never understand it's something that's kind of a the insides of an automated theorem proving system or something that a kind of a lot of structure or the insides of a machine Learning System where we look at it and we say well that's interesting it works nicely it picked out some features we don't understand what the features are it's not something it's beyond sort of human understanding but it's interesting to try to see can we get some kind of narrative understanding what's happening and I think the things the two things that we know about language one is that it has a definite syntactic grammar you know we know nouns and verbs go in the places they go it's one thing we know the other thing we know is that logic Works in language I mean when logic was originally invented by Aristotle and so on back in Antiquity you know I've got my imagination of what Aristotle did is something much like a machine Learning System would do he looked at lots of examples of rhetoric and he said what are some patterns of how language Works in these pieces of rhetoric that are sort of making arguments and so on what are the patterns of language that successfully make arguments and from that he extracted your syllogistic logic the you know all men and Mortal Socrates a man therefore Socrates is a mortal type thing those those kinds of structures he he extracted from language this kind of uh superstructure that is that is the kind of uh abstract logic and and from that much later in the 1800s you know Bool and people made it more mathematical made a kind of tower out of logic that goes beyond what is what is represented directly in language but I think what we're seeing in in tragedy PT is is it sort of discovered and we don't yet know what these precise patterns are but it's discovered kind of a semantic grammar of language and I think what the way we can think about what it's doing is it is putting together essentially these puzzle pieces just like when you make us a syntactic grammar of language you're defining these are the kind of trees and so on that you can put together these are the parse trees you can put together to form a a syntactically reasonable sentence well it's finding the things that will allow you to put together a semantically reasonable sentence essay whatever else and so I think that's kind of that's my sort of uh understanding of what it's doing now if you say is there an underlying sort of understanding that it has again I I consider that a very floppy question I consider that the the sort of the really well-grounded version of that question is can we turn it into something computational from which we can then use a a precise formal system.

The first line is the heading. Add two new lines after the heading and then punctuate it.

Feeding information back into the model 

 

To go and figure out things from it or even maybe the next step might be, can we once we had that structure and we can perform computation on it through Wolfram Alpha, for example, can we then turn around and turn that into action that we can take into the world that has, you know, certain desired effects? And this is what I wanted to ask you. Is okay, Bing came along and sort of provided some computation to um GPT, but very restricted, you know, restricted to searching and that sort of thing. Wolfram Alpha now finally gives it the power of full complete Turing complete anything goes, you know, kind of calculation. If we now allow it to feedback on itself, so this system Chad gbt plus plus Wolfram Alpha, if it's now able to say put information back into the info sphere, send out tweets, put stuff on a web page that can then come back through, you know, the GPT, you know, engine which as you say we may never understand it, it may just always be kind of a black box to us, but it can add its little bit of natural language magic and complete the circle, we now have almost this massive turing machine that has these hybrid components to it, you know, is this potentially the first step towards artificial general intelligence or are there still some missing ingredients?

Well, I think that the thing you, the picture you paint, one of the points that I think you're making is in a sense Church EBT on its own is reconstituting what US humans have already written on the web and in books and things like that. It's putting it together in novel ways, but it's sort of the same pieces. It's not creating new knowledge. As soon as you have actual computation in the loop and what I would talk about as irreducible computation, you can build what amounts to new knowledge. And so yes, it surely is the case that you know you ask chat TPT plus Wolfram some question, it goes off, it creates a piece of language code or something, it goes and runs somewhere, it finds new knowledge, it could then if it wanted to, it could tweak that new knowledge and then that new knowledge could get incorporated into the kind of uh into the Corpus of knowledge, a corpus of language that can be used by chat gbt and so on. So yes, I think that the thing that is uh, you know, the way to perhaps think about this is uh, in the end, you know, there's sort of a whole separate civilization of the AIS that is is in the process of developing. I mean, we already see that a whole bunch in uh, in the things that operate on on the web today and so on, but I think we'll see we'll see an increasing amount of that going forward and it's kind of uh, you know, the way I've been curious thinking about sort of so what's going to happen to all of us and the you know when the civilization of the AIS is is there and what will it feel like to be in a world where a lot of what happens is happening in kind of the AI sphere and not in the human sphere already a lot of that is happening. I mean already a lot of things that you know we're presented with on on the web and things like that come out of AI like processors not out of some kind of uh human decision making, but I think you know the way I the the analogy is is really our experience of the natural world. The natural world is full of what I think of as computational processes going on that that are ones that we don't intrinsically understand. The natural world just does what it does. We have found a way to exist sort of to coexist with the natural world. We've had the convenient feature that we've had a few billion years of biological evolution to figure out how to do that. It's a little bit of a different situation with the the kind of uh with with AI, although we have the the perhaps advantage that AIS are right now things which are created as a sort of uh as a as a result of the things that the Corpus of of material that we've put on the web. I mean, I think the thing to understand about what's happening with computation and Ai and so on is computation is a very broad kind of thing. You can, you know, if you just pick a program at random, this is something I've been uh, very much involved in over over the decades actually, is asking if you take a very simple program like a cellular automaton program or sharing machine for that matter and you just say I'm going to pick the rules for this thing, let's say at random and they're tiny rules, let's say just you're know 405 rules, six rules, whatever, and then you say well what does the system do, you might say based on our experience with engineering and so on, oh it won't do anything interesting and complicated because it's such a simple set of rules, that turns out not to be true, that's something I discovered in the 1980s to my great surprise, it took me a number of years to kind of come to terms with that discovery that even extremely simple rules are capable of generating extremely complicated Behavior that's a phenomenon of the computational universe that we're not particularly used to from our experience in engineering because in engineering we usually we want to do things where we can foresee the output, but so what happens is in the computational universe kind of there's immensely complex things that can be produced even with very simple programs, the question is are those things things that we humans in a sense care about, are they things for which we humans which we humans would talk about in the usual things that we want to do and so I think this idea that of sort of creativity, computational creativity, yes there's an infinite supply of computational creativity, the challenges of those things that are created which are ones that we humans sort of care about, which are ones where in the development of our civilization our natural language things like this we've actually got to the point where we where we think about those kinds of things, uh, you know, there are plenty of examples in in history of I don't know phenomena and physics where you know who cared about liquid crystals until we realized that we could make displays out of them things like this it's sort of what becomes something about which we humans kind of care and this sort of there's a there's as I say an infinite supply of kind of computational creativity out there which is certainly is now accessible for example to chat GPT but if it goes off and starts running simple programs and produces all sorts of complicated output people will say well that's nice but but you know it's until until we get to the point where we have kind of a a human narrative that kind of encompasses the kinds of things that are going on there until we have a reason to care it's just out there in the computational universe.

Semantics and cognitive categories 

 

Not something pulled into kind of the human sphere. I would love to explore this concept of creativity a little bit. I mean, first of all, reading your book was um, it was incredible. It opened up the whole world of emergence to me. And in a sense, you can think of um, a large language model as being a dynamical system, but it's sclerotic in the sense that it's been trained and now it's frozen. 

Something I was thinking about earlier was the irony that we almost never need to train it ever again because now we can prompt it on how to use Wolfram and how to create these neurosymbolic architectures. And it's almost like we don't need to change it anymore. But then if you look at um, the representations it's learned and the way that um, our cognitive categories emerge over time, these are things that are baked into the language model. But the language models aren't very good at learning new things, that continual learning. And this kind of brings us to this semantic grammar thing. You know, I just wondered what your thoughts were on the underlying model of the world that a semantic grammar assumes because when we're talking about cognitive categories, having it fixed isn't necessary really what we want, right? 

Interesting point. So, you know, one of the things that in a sense I find, you know, I'm just sort of coming to terms with it, is in a sense, you know, Church EBT and large language models in general are, as you say, taking a snapshot of the world as we humans have created it. And they're just saying, "Okay, this is now the standard, you know, every essay should now be written this way because this is the average of what the world has produced so far." And it's kind of a funny time. It's sort of a standards moment for a lot of kinds of knowledge work and so on. And it's a little bit of a strange thing because it's kind of, it now becomes, it's just like, you know, in the past there were probably no doubt, you know, all sorts of creative ways, I don't know, people might have written things by hand or done this or that. And then we have, you know, the fixed idea of it's a font and everybody gets to, you know, set the have the thing look the same way. So we've now done that for a large chunk of kind of knowledge work. And the question of sort of how we of how we, how we still keep doing new things, that's an interesting question. And I think that uh, you know, computation is the is the giant escape valve so to speak because it allows us to do huge numbers of new things. The issue is does our understanding kind of follow along with the actual sort of ability of computation to to kind of create the news so to speak. And I think that's a those are those are really interesting questions. 

You know, I think the thing to understand uh, kind of if we think about the sort of computational Universe of all possibilities, this is something you know, I've been last few years we've had these big breakthroughs that uh, I didn't think would happen in my lifetime but I'm really happy that they have with uh, thinking about fundamental physics and computational terms. And that's led to this kind of big idea of this thing we call the rouliad which is kind of the entangled limit of all possible computations. Imagine you start all possible Turing machines with all possible initial types. You start them all off together and you sort of simply look at what states those things produce. So there might be two touring machines that produce different states and then later on those States will be will converge because they'll end up being the same. And you get this this kind of giant structure. And one of the things that's sort of a a big result is we think that giant structure is kind of the thing that's underneath all of physics and all of mathematics. And kind of our experience of the physical world is our we are embedded within this rule ad and our experience of the physical world is taking some slice of that rouliad experiencing kind of the set of.

[Navigating the Ruliad]

All possible computations in a particular slice that corresponds to the ways that we kind of that our sensory data work and that our minds work. And I mean just to just to say one sort of science point, the big result I suppose is that if you put only a small set of constraints on the way that we observe what's happening in the Ruliad, actually really two constraints, one is that we are computationally bounded, we're limited in the computations we can do, the other constraint is we believe that we are persistent in time, even though at every moment we get made from different atoms of space, we have the belief and the experience that there's a thing that we persist through time. Those two constraints alone are enough to basically tell you that the slice of the Ruliad that we observe will satisfy physics as we know it. In fact, specifically the three big theories of 20th century physics, general relativity, the theory of gravity, quantum mechanics, and the statistical mechanics to second law of Thermodynamics and so on. The amazing thing that's become clear from stuff we've done last couple of years is that all three of those kinds of features of physics as we experience it are a consequence of us being observers of the kind we are observing this Ruliad of all possible computational processes. So that's sort of a big picture version of so the physics side of things, but that leads one to this view that sort of Minds experience the Ruliad experience this sort of entangled limit of all possible computations. It's like we are at a particular place in the Ruliad experiencing sort of the world in this particular way, just as we're at a particular place in physical space experiencing the world with respect to that place in physical space. And so you think about sort of different Minds as being different points at different points in the Ruliad. So different human Minds might be quite close in the to really add kind of the animals might be a bit further away the AIS are somewhere in the Ruliad. And what does it mean when we sort of make progress in making new paradigms about thinking about things? The way I see it is it's kind of an expansion in rural space. We are able to encompass more ways of thinking about the world than we could before. That's sort of the advance of paradigms, the increase of abstraction in fields like mathematics or science or whatever else. And sort of we're sort of gradually expanding in rural space, able to encompass more kinds of ways of looking at this kind of ultimate computational structure. So I think that the this kind of um the thing that that we see as we, you know, the growth of our uh kind of well uh sort of the intellectual history of our civilization can be thought of as this kind of gradual colonization of rule space. And that that's the and it's something that seems to happen quite gradually. It's not, you know, you can easily just sort of pick a random program and jump to an arbitrary place in real space. The problem is that there won't be much human that you can say about it. It will be just it's a program, it runs, uh, it looks, uh, but we we don't have a way of kind of describing what's going on. I think that's sort of the limiting factor. And I think what will be interesting to see is you know, can we can we kind of go on expanding? Okay, we've got our large language models which are trained from the way the world is today. Can they tell us, oh, there's this new concept that's really worthwhile? Can we deduce from sort of the computational world and the world of large language models and so on, there's this obvious concept that you humans should be learning about? You know, this is a direction that's worth going in. You know, there's an analogy of this. I happen to have made a big study of the foundations of mathematics. You know, in mathematics, it's very easy given an axiom system for some some area of mathematics, for example, to just enumerate all the possible theorems of of a reason principle, at least to enumerate all the possible theorems of let's say logic or geometry, whatever else. You get this giant entangled limit of all these possible theorems. The question is which ones have we humans chosen to actually talk about? There's a there's sort of infinite number of possible theorems, but there's only sort of an infinite space of possibilities, but only some places have we chosen to sort of colonize and describe. And so sort of the you can think of the kind of the history of mathematics as being following these particular paths in kind of meta mathematical space of of all the possible things that one could be thinking about all the possible theorems one could be one could be uh considering. And so I think it's sort of this interesting thing in the in the world in general, what is it that we could be thinking about about the world that we aren't thinking about right now? Give you an example that um uh so you know fractal patterns nested patterns right things that we've known about you know sort of popularized to the last I don't know three or four decades and sort of known about for about 100 years. Well, actually, those kinds of nested patterns so far as I know were first invented by a mosaic layer in Italy in the 1200s early 1200s made this thing that particular person died the uh you know the the art of making that particular nested pattern disappeared the art historians wrote about many of the mosaics done by this family of Mosaic layers they never mentioned the nested patterns they talked about you know the birds and lions and so on but they were completely blind to this idea of nested patterns which then in recent times everybody would see this pattern say oh that's a fractal pattern um but uh you know this is the kind of example of how sort of when you have a new paradigm for thinking about things you kind of noticed things you didn't notice before and a very interesting question is what things are there in the world that we have noticed before in my own life the the sort of the biggest one that was this phenomenon that I already mentioned about how simple programs can lead to extremely complicated behavior that's a very fundamental scientific result that has all kinds of implications but that's a result which as I say after I had first done computer experiments that plainly showed that result it still took me several years to kind of realize oh that's a real you know that's a real thing and when I look back I realized there were zillions of examples of this that existed for hundreds of years where people just ignored it I mean you know you look at it yeah yeah I wonder if I could jump in here because what you're saying is it's truly fascinating it's the idea that that these AIS could help us navigate this impossibly vast you know space of possible com you know computation the ruly ad but there's also the other way around which is us helping them navigate and as you pointed out in this kind of wonderful essay back in February you know what was yeah what is GPT doing and why does it work you know in this impossibly vast space they're sort of total pure chance there's complete randomness and at this narrow boundary between there's really chaos which is where all the interesting stuff happens it's where the irreducibly complex computations are it's where Turing machines are it's where all this rich behavior is kind of on that on that boundary and it's almost the sliver and like you said finding the programs in this vast space that are useful to humans or do something interesting is really difficult and and we've kind of been discovering over time that as you build systems that are more and more capable they become harder and harder to train and you talk about this a lot in your essay and you're optimistic that we're going to find ways to to train you know these ever more capable systems effectively and efficiently and uh I'm wondering how you think we're going to achieve that like what what's going to be the key to it what avenues of research are promising to take us down that path of navigating the ruly ad?

to attention to and so on that's kind of an interesting question and I think it's something that we're just beginning to be able to address because we have these large language models that have been trained on sort of the corpus of human knowledge and human communication so it's kind of an interesting time to be thinking about these things but I think the the key point that I wanted to make here is just this notion of computational irreducibility and how it's kind of a fundamental limitation of science but it's also something that gives us sort of the richness of the computational universe and the fact that there are things that we can't just immediately predict and that there's sort of a richness to the passage of time and the computation that happens over time that we wouldn't have if everything were just immediately predictable so that's kind of the key point that I wanted to make here.

Conceivability and interestingness 

Names to yes, I wholeheartedly agree that the gradient of interestingness is very important, but I also want to bring in the gradient of conceivability. Just before I do that, I wanted to comment on you referring to it as a linguistic interface, and I'm glad that you did because it's an interface that can be used by many people in many different situations. But the key thing is that it's about being intelligible rather than being a conversational interface. 

But on this notion of conceivability, you said something fascinating, which is that there's this Mosaic, and it was interesting to people let's say hundreds or even thousands of years ago, and then it became lost. Nagel's thought experiment about the bat is a subjective form of conceivability, and Noam Chomsky talks as a nativist about the domain of things which are conceivable as a function of the cognitive prize which are in our brain. So there's this trajectory space of things which are conceivable, and it's almost like we're cheating by creating these computational models which can subject to irreducibility can compute all of these different things. But the key question is whether or not we would recognize something as being interesting or whether it would be conceivable even if it were present, right? 

So, I think this is the thing, progress is gradual and slow. In other words, if you jump to some random place in the rouliad, you pick a random program, you look at it, you know when you first look at it, it's like, "I don't know why I care about this." It's something where you have to have a kind of a cognitive or intellectual history kind of path that gets there. We don't get to talk about the until we've built sort of the ambient ideas until we built this kind of intellectual path. It isn't really, it doesn't really work to just jump to that place. It's like I could make up a word and I don't know, I could make up a word for, I don't know, let's say look at clouds in the sky and they have all kinds of weird different shapes and we have a few names for a few of those shapes right now. We don't have a reason to care about the particular details of those shapes, but you know I can make up a word for one of those things, but until I can sort of tell you why we care about that, it becomes something that's very hard to, it's something we're sort of not connected to. 

I kind of think it's one of these things where it is there's sort of a sense of gradual progress, but you kind of can't, it's a, it's, you can't kind of jump ahead. It's kind of like the computational irreducibility story actually that you can't kind of jump to a random place and expect to have understanding there. Well, it may be the case too, maybe we don't need to understand it, right? Because as long as let's say the AI is producing structured Concepts, even if we don't understand those Concepts, if they're structured enough that programs in Wolfram Alpha can make use of them to produce actions, let's say in the world that are good for us, then we may not even need to understand those Concepts at least not yet. 

Right, I think this is the kind of question of, once we Define the goals, how those goals get implemented is something that is a matter of interest for science, but it's not necessarily a matter of relevance for the people using it. And I think this is the thing which is sort of an interesting phenomenon in well the history of computing particularly is what is it that you're trying to get out of a computer? Well, you're trying to achieve certain goals, you're trying to, and this is where my sort of lifelong story of kind of the programming languages versus the full-scale computational language idea, you know, the programming languages which are really talking to computers in terms that computers intrinsically understand, you know, set this up this array, you know, and move this, do this Loop, change this value from this to this to this, that's the sort of the computer's intrinsic understanding. 

I think that the thing I've long been interested in is how do we go from something that is the way we think about things, how do we make a bridge between the way we think about things and what is possible computationally? And the thing that has been my long time effort is to build our computational language, well from language to be able to sort of be that bridge between the way we think about things, the things we think about, and what is computationally possible. So, I think the this question of relating, well, let's see, the I think I didn't respond to what you, you would say something interesting, and I think I lost my thread of what you were, what you were, what you were.

Human Intelligible Sciences 

was it was really um, I think what I'm trying to find out is what role human beings, you know, are actually going to play in building the better architectures of tomorrow because, because you made a point in that article from February that, you know, right now, to be honest, the construction of these architectures is an art. It's really just people do some trial and error, they come up with some horseshoes or whatever shape, you know, of uh, of architecture happens to work, you know, GPTs and that's, you know, same kind of category. You point out there's no real science, you know, behind that and on the one hand, we could defer all that science to AIS potentially and maybe we'll never understand the science that they do to build the next better versions of themselves, but I'm wondering if you also have any space in your vision for us developing human intelligible sciences that can do a better job of this and if so, like what might they look like and what other Sciences might they resemble, zoology, you know, I don't know, right? So I think the thing, okay, so this question of uh, uh, sort of so this thing that's going on inside that's very complicated that's computationally irreducible, what can we say about it? And you know, we can still have something where there's complicated computations going on, they achieve goals we're interested in, we're happy, we're done. We can then go in, as you, as you point out, and ask what's the science of what's happening inside? In a sense, the Neuroscience has been that story of we know what we humans do, you know, how does we know something about how the microscopic brain, uh, you know, works and you know, neuron firings and so on. We don't have an Intermediate Language of Neuroscience that is kind of the thing that is above the level of individual neuron firings and below the level of psychology, basically. And I think that that's, um, the question of can you find that and when can you find that? It's a very interesting question. I think one of the things that is a science point that when you have computational irreducibility, one of of the necessary consequences of computational irreducibility is within a computational irreducible system that will always be an infinite number of specific little pieces of computational reusability that you can find. In other words, even though you can't say everything, there are lots of little pieces that little things you can say. In a sense, that's why, you know, if we take it at a more General level, if you say, well, what inventions can we make given the physical world which has computational irreducibility, what things can we predict, what things can we invent which have foreseeable behavior and so on, and the answer is there will be, there will be an infinite collection of these things. We'll never run out of inventions, little pieces of computational reducibility that we can find in this ultimately computational irreducible Universe in which we live. So in a sense, we're always, we're always finding these little jumps, little pieces of computational reducibility, and those pieces of computational reducibility may be big enough that we can kind of live in them. You know, the fact that we believe space is continuous, that is a feature of a slice of computational reducibility from the underlying computational irreducibility of this complicated, as you know, the way we've set it up with this, you know, rewriting rules for some hypergraph that's going on underneath. That's a very complicated thing. If we were stuck, you know, experiencing the world in terms of this typograph being Rewritten all the time, we wouldn't be able to sort of go and Lead our lives in a simple ways. It's like, you know, when you have molecules and a gas bouncing around, if we had to follow every molecule, that would be a very different thing from our typical experience of a gas, which is just this sort of continuous fluid. So I think the thing that that um, uh, in we're we're kind of we experience, it's very important to find these sort of slices of computational reducibility because they're the things that we can build engineering, we can make a predictable life out of and so on, and those are things which again in uh, but but many of those, you know, the the many of those pieces of computational reducibility we haven't yet found, we don't yet have names for. As we find them, we may be able to make use of them and we may be able to kind of uh, expand our experience of of the world um, in a way which which makes use of those things. But I think in um, uh, and you know, is it the case that sort of uh, we'll be able to use uh, well, you're asking kind of for example, one one question you can ask is will there be a science of machine learning that would be a reasonable kind of question, you know, is it is it going to be the case, you know, right now people say, well, uh, what might a science of machine learning look like? Well, that's an interesting question. It's uh, the you know when uh, here's an example. So typically a machine learning, you, you know, you do a training, you're finding, you know, you're finding a particular path where you get to a a good point where you have a nice trained neural Nets. Imagine you followed all possible paths. It'd be a computationally absurd, you know, thing to do, but the universe does